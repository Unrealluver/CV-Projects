{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import *\n",
    "from random import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (50000, 3072) (50000,)\n",
      "test:   (10000, 3072) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "data_dir=\"../cifar-10-batches-py/\"\n",
    "'''\n",
    "data files contain three binary part.\n",
    "batch_label: which represents the index of the dataset.\n",
    "labels: which represents the category of the images, \n",
    "        the index of the row is also the row index of the image.\n",
    "data: which is the image data that has 3072 columns, \n",
    "        the first 1024 columns represent the red channels of the 32x32 image, \n",
    "        the next 1024 columns represent the green one, \n",
    "        the last represent the blue one.\n",
    "filenames: which is the name of the images.\n",
    "'''\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def get_batch_data():\n",
    "    batch_train=[]\n",
    "    for i in range(1, 6):\n",
    "        batch_train.append(unpickle(data_dir + \"data_batch_\" + i.__str__()))\n",
    "\n",
    "    batch_test = unpickle(data_dir + \"test_batch\")\n",
    "    return batch_train, batch_test\n",
    "\n",
    "train_list,test_list= get_batch_data()\n",
    "train_X = np.array(train_list[0].get(b'data'))\n",
    "train_y=np.array(train_list[0].get(b'labels'))\n",
    "for i in range(1,len(train_list)):\n",
    "    train_X = np.concatenate((train_X,train_list[i].get(b'data')),axis=0)\n",
    "    train_y = np.concatenate((train_y,train_list[i].get(b'labels')),axis=0)\n",
    "\n",
    "train_images = train_X/255.0\n",
    "train_labels=train_y    \n",
    "test_images = np.array(test_list.get(b'data'))/255.0\n",
    "test_labels = np.array(test_list.get(b'labels'))\n",
    "print(\"train: \",train_images.shape,train_labels.shape)\n",
    "print(\"test:  \",test_images.shape,test_labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def make_one_hot(data):\n",
    "    return (np.arange(10)==data[:,None]).astype(np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_images_with_noise=train_images+np.random.randn(train_images.shape[0],train_images.shape[1])/5\n",
    "onehot_train_labels=make_one_hot(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_loss(model, X, y):\n",
    "    num_examples = X.shape[0]\n",
    "    batch_size=num_examples\n",
    "    t=ceil(num_examples/batch_size)\n",
    "    y_=[]\n",
    "    for j in range(t):\n",
    "        a=X[batch_size*j:batch_size*(j+1)]\n",
    "        for k in range(len(nn_hdim)+1):\n",
    "            z=np.matmul(a,model['W'][k])+model['b'][k]\n",
    "            if k!=(len(nn_hdim)):\n",
    "                a=(abs(z)+z)/2\n",
    "            else:\n",
    "                exp_scores=np.exp(z)\n",
    "                a=exp_scores/np.sum(exp_scores,axis=1,keepdims=True)\n",
    "        if len(y_)==0:\n",
    "            y_=a\n",
    "        else:\n",
    "            y_=np.vstack([y_,a])\n",
    "    print(len(y_))\n",
    "    print(len(y))        \n",
    "    corect_logprobs = -np.log(y_[range(num_examples), y]+1e-10)\n",
    "    data_loss = np.sum(corect_logprobs)\n",
    "    # Add regulatization term to loss (optional)\n",
    "    for j in model['W']:\n",
    "        data_loss+=(reg_lambda/2)*np.sum(np.square(j))\n",
    "    return (1. / num_examples) * data_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model,x):\n",
    "    a=x\n",
    "    for j in range(len(nn_hdim)+1):\n",
    "        z=np.matmul(a,model['W'][j])+model['b'][j]\n",
    "        if j!=len(nn_hdim):\n",
    "            a=(abs(z)+z)/2\n",
    "        else:\n",
    "            exp_scores=np.exp(z)\n",
    "            a=exp_scores/np.sum(exp_scores,axis=1,keepdims=True)\n",
    "    return np.argmax(a,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "nn_hdim=[300,300,300,300]\n",
    "input_dims=train_images.shape[1]\n",
    "output_dims=10\n",
    "all_dim=[input_dims]+nn_hdim+[output_dims]\n",
    "model={'W':[],'b':[],'hd':nn_hdim}\n",
    "W=model['W']\n",
    "b=model['b']\n",
    "for i in range(len(nn_hdim)+1):\n",
    "    W.append(np.random.randn(all_dim[i],all_dim[i+1])/np.sqrt(all_dim[i+1]))\n",
    "    b.append(np.zeros((1,all_dim[i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2898\n"
     ]
    }
   ],
   "source": [
    "n=ceil(train_images.shape[0]/batch_size)\n",
    "w_num=len(nn_hdim)\n",
    "W=model['W']\n",
    "b=model['b']\n",
    "for i in range(epochs):\n",
    "    for j in range(n*2):\n",
    "        if j<n:\n",
    "            xx=train_images[batch_size*(j%n):batch_size*((j+1)%n)]\n",
    "        elif j<2*n:\n",
    "            xx=train_images_with_noise[batch_size*(j%n):batch_size*((j+1)%n)]\n",
    "        yy_onehot=onehot_train_labels[batch_size*(j%n):batch_size*((j+1)%n)]\n",
    "        #yy=train_images[batch_size*j:batch_size*(j+1)]\n",
    "        dW=[]\n",
    "        db=[]\n",
    "        z=[]\n",
    "        a=[]\n",
    "        drop=[]\n",
    "        a.append(xx)\n",
    "        for k in range(w_num+1):\n",
    "            z_temp=np.matmul(a[-1],W[k])+b[k]\n",
    "            if k!=w_num:\n",
    "                drop.append(np.less(np.random.uniform(size=z_temp.shape),remain_pro)/remain_pro)\n",
    "                z_temp*=drop[-1]\n",
    "            z.append(z_temp)\n",
    "            if k!=w_num:\n",
    "                a.append((abs(z_temp)+z_temp)/2)\n",
    "            else:\n",
    "                exp_scores=np.exp(z_temp)\n",
    "                a_temp=exp_scores/np.clip(np.sum(exp_scores,axis=1,keepdims=True),a_min=1e-10,a_max=None)\n",
    "                if np.isnan(a_temp).any():\n",
    "                    raise ValueError('there is a nan')\n",
    "                a.append(a_temp)\n",
    "        # a: xx a1-an\n",
    "        # z: z1-zn        \n",
    "        for k in range(w_num+1):\n",
    "            if k==0:\n",
    "                delta=a[-1]-yy_onehot\n",
    "            else:\n",
    "                delta=np.matmul(delta,W[w_num+1-k].T)*((np.sign(a[w_num+1-k])+1.)/2.)*drop[w_num-k]\n",
    "            dW.append(np.matmul(a[w_num-k].T,delta))\n",
    "            db.append(np.sum(delta,axis=0))\n",
    "            #先是Wn,才识W1\n",
    "        temp_reg_lambda=reg_lambda\n",
    "        for k in dW:\n",
    "            k+=temp_reg_lambda*k\n",
    "            temp_reg_lambda*=1.5\n",
    "        for i in range(w_num+1):\n",
    "            W[i]-=learning_rate*dW[w_num-i]\n",
    "            b[i]-=learning_rate*db[w_num-i]\n",
    "    if i%1==0:\n",
    "        yp=predict(model,test_images)\n",
    "        one_acc=np.equal(yp,test_labels).mean()    \n",
    "        print(one_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate=0.00002\n",
    "reg_lambda=0.008\n",
    "epochs=1\n",
    "batch_size=1000\n",
    "remain_pro=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3829\n"
     ]
    }
   ],
   "source": [
    "yp=predict(model,test_images)\n",
    "print(np.equal(yp,test_labels).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "name": "dl.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
